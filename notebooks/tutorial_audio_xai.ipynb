{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncommen and run this cell to use Google Colab\n",
    "# !git clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.realpath('../'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "UghxXB-ZKzdi"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "from typing import Dict, List, Union, Any, Tuple, Iterable\n",
    "\n",
    "# from google.colab import userdata\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utils\n",
    "import models\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UB54vyDLkJFA"
   },
   "source": [
    "## Download Data and Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists at: data/ravdess/ravdess.zip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('data/ravdess')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ravdess_link = 'https://zenodo.org/record/1188976/files/Audio_Speech_Actors_01-24.zip?download=1'\n",
    "data_dir = utils.download_file(url=ravdess_link,\n",
    "                               file_name=\"ravdess.zip\",\n",
    "                               cache_dir= './data/ravdess',\n",
    "                               extract=True,\n",
    "                               force_download=False,\n",
    "                               archive_folder='')\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "HexKC1cxBcfe"
   },
   "outputs": [],
   "source": [
    "basepath = Path('./output')\n",
    "\n",
    "output_path = basepath / 'ravdess'\n",
    "feature_path = output_path / 'features'\n",
    "audio_path = output_path / 'audio_clips'\n",
    "model_path = output_path /'model'\n",
    "\n",
    "os.makedirs(feature_path, exist_ok=True)\n",
    "os.makedirs(audio_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "ufap5o3v07bg"
   },
   "outputs": [],
   "source": [
    "def get_log_melspec(data, sample_rate, silence_thresh=25):\n",
    "  \"\"\"\n",
    "  Function for extracting features from an audio sample.  The audio is preprocess to remove silence and then\n",
    "  padded on both sides to ensure each clip is 5 seconds.\n",
    "  Then the log mel spectrogram is extracted.\n",
    "  \"\"\"\n",
    "  trimmed, _ = librosa.effects.trim(data, top_db=silence_thresh)\n",
    "  padded = np.pad(trimmed, (int(sample_rate*2.5-len(trimmed)//2), int(sample_rate*2.5-len(trimmed)//2)), 'constant')\n",
    "  mel = librosa.feature.melspectrogram(y=padded, sr=sample_rate, n_fft=2048, hop_length=512, n_mels=128)\n",
    "  return librosa.power_to_db(mel, ref=np.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "FVVn__5fO75F"
   },
   "outputs": [],
   "source": [
    "LABEL_DICT = {0:'neutral', 1:'calm', 2:'happy', 3:'sad', 4:'angry', 5:'fear', 6:'disgust', 7:'surprise'}\n",
    "LABEL_MAP_DICT = {v: k for k, v in LABEL_DICT.items()}\n",
    "LABELS = list(LABEL_DICT.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "u8YfKv9STbW3"
   },
   "outputs": [],
   "source": [
    "data = dict(\n",
    "    actor = [],\n",
    "    emotion = [],\n",
    "    intensity = [],\n",
    "    gender = [],\n",
    "    path = []\n",
    ")\n",
    "\n",
    "wav_files = data_dir.rglob('*.wav')\n",
    "\n",
    "for wav in wav_files:\n",
    "\n",
    "    _, _, emo, emo_int, _, _, actor = wav.stem.split('-')\n",
    "\n",
    "    data['actor'].append(int(actor))\n",
    "    data['emotion'].append(int(emo)-1)\n",
    "    data['intensity'].append(int(emo_int))\n",
    "    data['gender'].append('male' if int(actor) % 2 == 0 else 'female')\n",
    "    data['path'].append(str(wav))\n",
    "\n",
    "df_rav = pd.DataFrame.from_dict(data)\n",
    "df_rav['emotion_label'] = df_rav.emotion.replace(LABEL_DICT, inplace=False)\n",
    "\n",
    "# extract features and save to dataframe\n",
    "def load_melspec(row):\n",
    "  a, sr = librosa.load(row['path'], sr=16000)\n",
    "  return get_log_melspec(a, sr, silence_thresh=55)\n",
    "\n",
    "df_rav['feats'] = df_rav.apply(load_melspec, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "NWmTd__rz1Ix"
   },
   "outputs": [],
   "source": [
    "# validate extracted features\n",
    "for idx, row in df_rav.iterrows():\n",
    "  assert row.feats.shape == (128, 157), f'shape: {row.feats.shape}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "kb7bbBOiRAey",
    "outputId": "664f6418-8b62-4f30-cbef-1ee7221c9eb2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actor</th>\n",
       "      <th>emotion</th>\n",
       "      <th>intensity</th>\n",
       "      <th>gender</th>\n",
       "      <th>path</th>\n",
       "      <th>emotion_label</th>\n",
       "      <th>feats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>data/ravdess/Actor_15/03-01-03-01-02-02-15.wav</td>\n",
       "      <td>happy</td>\n",
       "      <td>[[-80.0, -80.0, -80.0, -80.0, -80.0, -80.0, -8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     actor  emotion  intensity  gender  \\\n",
       "838     15        2          1  female   \n",
       "\n",
       "                                               path emotion_label  \\\n",
       "838  data/ravdess/Actor_15/03-01-03-01-02-02-15.wav         happy   \n",
       "\n",
       "                                                 feats  \n",
       "838  [[-80.0, -80.0, -80.0, -80.0, -80.0, -80.0, -8...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# review one row\n",
    "df_rav.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I7a0Jb9dYXLd"
   },
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "CTb7m6VW84YB"
   },
   "outputs": [],
   "source": [
    "# # split dataset by actors\n",
    "# all_actors = df_rav['actor'].unique()\n",
    "# actors_gender = df_rav.groupby('actor')['gender'].unique().reset_index()\n",
    "\n",
    "# train_actors, tmp = train_test_split(actors_gender, train_size=10, stratify=actors_gender['gender'], random_state=36851234)\n",
    "# val_actors, test_actors = train_test_split(tmp, train_size=8, stratify=tmp['gender'], random_state=36851234)\n",
    "\n",
    "# train_actors = train_actors['actor'].tolist()\n",
    "# val_actors = val_actors['actor'].tolist()\n",
    "# test_actors = test_actors['actor'].tolist()\n",
    "\n",
    "# df_train = df_rav[df_rav['actor'].isin(train_actors)]\n",
    "# df_val = df_rav[df_rav['actor'].isin(val_actors)]\n",
    "# df_test = df_rav[df_rav['actor'].isin(test_actors)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "3UWWdOrPqJ3q"
   },
   "outputs": [],
   "source": [
    "# Random data set split\n",
    "df_train = df_rav.sample(frac=.8, random_state=0)\n",
    "df_val = df_rav.drop(df_train.index).sample(frac=.5, random_state=0)\n",
    "df_test = df_rav.drop(df_train.index).drop(df_val.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Pytorch Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "OI7xziIfbEiy"
   },
   "outputs": [],
   "source": [
    "def get_dataset(df, feats_col, labels_col):\n",
    "  labels = df[labels_col].values\n",
    "\n",
    "  # convert from object array in dataframe to floats\n",
    "  # and convert to numpy array\n",
    "  feats = df[feats_col]\n",
    "  feats = [f.astype(float) for f in feats]\n",
    "  feats = np.array(feats)\n",
    "  feats = feats[:, None, :, :]\n",
    "\n",
    "  idxs = df.index.values\n",
    "\n",
    "  # Setup features and labels as tensors\n",
    "  X = torch.tensor(feats, dtype=torch.float32)\n",
    "  y = torch.tensor(labels, dtype=torch.long)\n",
    "  idxs = torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "  # Create TensorDataset\n",
    "  dataset = TensorDataset(X, y, idxs)\n",
    "\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "744K7mpLiO2K"
   },
   "outputs": [],
   "source": [
    "# setup dataloaders based on previous dataset split\n",
    "ds_train = get_dataset(df_train, 'feats', 'emotion')\n",
    "ds_val = get_dataset(df_val, 'feats', 'emotion')\n",
    "ds_test = get_dataset(df_test, 'feats', 'emotion')\n",
    "\n",
    "dl_train = DataLoader(ds_train, batch_size=64, shuffle=True)\n",
    "dl_val = DataLoader(ds_val, batch_size=1, shuffle=False)\n",
    "dl_test = DataLoader(ds_test, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uof__9L0kOiE"
   },
   "source": [
    "# Load and Evaluate Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded to: data/ravdess/model/ravdess_model.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('data/ravdess/model/ravdess_model.pth')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get checkpoint\n",
    "ckpt_link = 'https://uni-bielefeld.sciebo.de/s/eiOiBrhuOENmo0p/download'\n",
    "ckpt_path = utils.download_file(ckpt_link, \n",
    "                                'ravdess_model.pth',\n",
    "                                cache_dir='./data/ravdess/model',\n",
    "                                extract=False,\n",
    "                                force_download=False\n",
    "                                )\n",
    "ckpt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ecIc95PzS8Ui",
    "outputId": "27a437f3-5207-4c08-8578-5733c0e2065a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e9guXuR1Swjz"
   },
   "source": [
    "# Load and Evaluate Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RH7RBT4qSwRR",
    "outputId": "0bd0ee58-b179-4cbd-ea22-673c14f9cde0"
   },
   "outputs": [],
   "source": [
    "# To load the best model:\n",
    "model = models.ResNet(len(LABELS))\n",
    "model.load_state_dict(torch.load(ckpt_path, map_location='cpu'))\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H-Td_Q1HVdM0",
    "outputId": "9c978f2c-c999-45d9-cf61-ca3bf560570c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Loss: 0.2378, Evaluation Accuracy: 0.9349\n",
      "Evaluation Loss: 0.0925, Evaluation Accuracy: 0.9792\n",
      "Evaluation Loss: 0.1880, Evaluation Accuracy: 0.9236\n"
     ]
    }
   ],
   "source": [
    "evaluate.evaluate_model(model, dl_train, criterion, device)\n",
    "evaluate.evaluate_model(model, dl_val, criterion, device)\n",
    "_, _, test_preds, test_probs = evaluate.evaluate_model(model, dl_test, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9236111111111112"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load probabilities and predictions into dataframe for test dataset\n",
    "df_test['pred'] = test_preds\n",
    "df_test['prob'] = test_probs\n",
    "test_corr = df_test['emotion'] == df_test['pred']\n",
    "test_corr.astype(int).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
