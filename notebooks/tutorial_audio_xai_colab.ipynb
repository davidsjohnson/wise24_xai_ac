{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidsjohnson/wise24_xai_ac/blob/setup/notebooks/tutorial_audio_xai_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yVuQNWa6bYJe",
        "outputId": "3fd20601-b48c-4677-d3b8-48b234939214",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'wise24_xai_ac'...\n",
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 12 (delta 2), reused 10 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (12/12), 8.79 KiB | 8.79 MiB/s, done.\n",
            "Resolving deltas: 100% (2/2), done.\n"
          ]
        }
      ],
      "source": [
        "# uncommen and run this cell to use Google Colab\n",
        "!git clone https://github.com/davidsjohnson/wise24_xai_ac.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jyYLHAw3bYJe"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append(os.path.realpath('wise24_xai_ac'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UghxXB-ZKzdi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import random\n",
        "\n",
        "from typing import Dict, List, Union, Any, Tuple, Iterable\n",
        "\n",
        "# from google.colab import userdata\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "import librosa\n",
        "import librosa.display\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import utils\n",
        "import models\n",
        "import evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyNs29MvbYJg"
      },
      "source": [
        "# Setup Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB54vyDLkJFA"
      },
      "source": [
        "## Download Data and Extract Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "l8PKCYw6bYJh",
        "outputId": "b23f5946-0875-4864-cc13-b8e5cdc4c62b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File downloaded to: data/ravdess/ravdess.zip\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('data/ravdess')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "ravdess_link = 'https://zenodo.org/record/1188976/files/Audio_Speech_Actors_01-24.zip?download=1'\n",
        "data_dir = utils.download_file(url=ravdess_link,\n",
        "                               file_name=\"ravdess.zip\",\n",
        "                               cache_dir= './data/ravdess',\n",
        "                               extract=True,\n",
        "                               force_download=False,\n",
        "                               archive_folder='')\n",
        "data_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HexKC1cxBcfe"
      },
      "outputs": [],
      "source": [
        "basepath = Path('./output')\n",
        "\n",
        "output_path = basepath / 'ravdess'\n",
        "feature_path = output_path / 'features'\n",
        "audio_path = output_path / 'audio_clips'\n",
        "model_path = output_path /'model'\n",
        "\n",
        "os.makedirs(feature_path, exist_ok=True)\n",
        "os.makedirs(audio_path, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ufap5o3v07bg"
      },
      "outputs": [],
      "source": [
        "def get_log_melspec(data, sample_rate, silence_thresh=25):\n",
        "  \"\"\"\n",
        "  Function for extracting features from an audio sample.  The audio is preprocess to remove silence and then\n",
        "  padded on both sides to ensure each clip is 5 seconds.\n",
        "  Then the log mel spectrogram is extracted.\n",
        "  \"\"\"\n",
        "  trimmed, _ = librosa.effects.trim(data, top_db=silence_thresh)\n",
        "  padded = np.pad(trimmed, (int(sample_rate*2.5-len(trimmed)//2), int(sample_rate*2.5-len(trimmed)//2)), 'constant')\n",
        "  mel = librosa.feature.melspectrogram(y=padded, sr=sample_rate, n_fft=2048, hop_length=512, n_mels=128)\n",
        "  return librosa.power_to_db(mel, ref=np.max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "FVVn__5fO75F"
      },
      "outputs": [],
      "source": [
        "LABEL_DICT = {0:'neutral', 1:'calm', 2:'happy', 3:'sad', 4:'angry', 5:'fear', 6:'disgust', 7:'surprise'}\n",
        "LABEL_MAP_DICT = {v: k for k, v in LABEL_DICT.items()}\n",
        "LABELS = list(LABEL_DICT.values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "u8YfKv9STbW3"
      },
      "outputs": [],
      "source": [
        "data = dict(\n",
        "    actor = [],\n",
        "    emotion = [],\n",
        "    intensity = [],\n",
        "    gender = [],\n",
        "    path = []\n",
        ")\n",
        "\n",
        "wav_files = data_dir.rglob('*.wav')\n",
        "\n",
        "for wav in wav_files:\n",
        "\n",
        "    _, _, emo, emo_int, _, _, actor = wav.stem.split('-')\n",
        "\n",
        "    data['actor'].append(int(actor))\n",
        "    data['emotion'].append(int(emo)-1)\n",
        "    data['intensity'].append(int(emo_int))\n",
        "    data['gender'].append('male' if int(actor) % 2 == 0 else 'female')\n",
        "    data['path'].append(str(wav))\n",
        "\n",
        "df_rav = pd.DataFrame.from_dict(data)\n",
        "df_rav['emotion_label'] = df_rav.emotion.replace(LABEL_DICT, inplace=False)\n",
        "\n",
        "# extract features and save to dataframe\n",
        "def load_melspec(row):\n",
        "  a, sr = librosa.load(row['path'], sr=16000)\n",
        "  return get_log_melspec(a, sr, silence_thresh=55)\n",
        "\n",
        "df_rav['feats'] = df_rav.apply(load_melspec, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "NWmTd__rz1Ix"
      },
      "outputs": [],
      "source": [
        "# validate extracted features\n",
        "for idx, row in df_rav.iterrows():\n",
        "  assert row.feats.shape == (128, 157), f'shape: {row.feats.shape}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "kb7bbBOiRAey",
        "outputId": "687fb095-5ba9-4d00-cf4c-eddd6c9c4b4c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     actor  emotion  intensity  gender  \\\n",
              "186      1        1          2  female   \n",
              "\n",
              "                                               path emotion_label  \\\n",
              "186  data/ravdess/Actor_01/03-01-02-02-01-01-01.wav          calm   \n",
              "\n",
              "                                                 feats  \n",
              "186  [[-80.0, -80.0, -80.0, -80.0, -80.0, -80.0, -8...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6df7ad02-f4ac-41ea-9e32-2a66d9e94fb5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>actor</th>\n",
              "      <th>emotion</th>\n",
              "      <th>intensity</th>\n",
              "      <th>gender</th>\n",
              "      <th>path</th>\n",
              "      <th>emotion_label</th>\n",
              "      <th>feats</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>186</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>female</td>\n",
              "      <td>data/ravdess/Actor_01/03-01-02-02-01-01-01.wav</td>\n",
              "      <td>calm</td>\n",
              "      <td>[[-80.0, -80.0, -80.0, -80.0, -80.0, -80.0, -8...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6df7ad02-f4ac-41ea-9e32-2a66d9e94fb5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6df7ad02-f4ac-41ea-9e32-2a66d9e94fb5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6df7ad02-f4ac-41ea-9e32-2a66d9e94fb5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_rav\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"actor\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"emotion\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"intensity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 2,\n        \"max\": 2,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gender\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"female\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"data/ravdess/Actor_01/03-01-02-02-01-01-01.wav\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"emotion_label\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"calm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"feats\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# review one row\n",
        "df_rav.sample(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7a0Jb9dYXLd"
      },
      "source": [
        "## Split Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "CTb7m6VW84YB"
      },
      "outputs": [],
      "source": [
        "# # split dataset by actors\n",
        "# all_actors = df_rav['actor'].unique()\n",
        "# actors_gender = df_rav.groupby('actor')['gender'].unique().reset_index()\n",
        "\n",
        "# train_actors, tmp = train_test_split(actors_gender, train_size=10, stratify=actors_gender['gender'], random_state=36851234)\n",
        "# val_actors, test_actors = train_test_split(tmp, train_size=8, stratify=tmp['gender'], random_state=36851234)\n",
        "\n",
        "# train_actors = train_actors['actor'].tolist()\n",
        "# val_actors = val_actors['actor'].tolist()\n",
        "# test_actors = test_actors['actor'].tolist()\n",
        "\n",
        "# df_train = df_rav[df_rav['actor'].isin(train_actors)]\n",
        "# df_val = df_rav[df_rav['actor'].isin(val_actors)]\n",
        "# df_test = df_rav[df_rav['actor'].isin(test_actors)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "3UWWdOrPqJ3q"
      },
      "outputs": [],
      "source": [
        "# Random data set split\n",
        "df_train = df_rav.sample(frac=.8, random_state=0)\n",
        "df_val = df_rav.drop(df_train.index).sample(frac=.5, random_state=0)\n",
        "df_test = df_rav.drop(df_train.index).drop(df_val.index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjbC8wAYbYJl"
      },
      "source": [
        "## Setup Pytorch Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "OI7xziIfbEiy"
      },
      "outputs": [],
      "source": [
        "def get_dataset(df, feats_col, labels_col):\n",
        "  labels = df[labels_col].values\n",
        "\n",
        "  # convert from object array in dataframe to floats\n",
        "  # and convert to numpy array\n",
        "  feats = df[feats_col]\n",
        "  feats = [f.astype(float) for f in feats]\n",
        "  feats = np.array(feats)\n",
        "  feats = feats[:, None, :, :]\n",
        "\n",
        "  idxs = df.index.values\n",
        "\n",
        "  # Setup features and labels as tensors\n",
        "  X = torch.tensor(feats, dtype=torch.float32)\n",
        "  y = torch.tensor(labels, dtype=torch.long)\n",
        "  idxs = torch.tensor(idxs, dtype=torch.long)\n",
        "\n",
        "  # Create TensorDataset\n",
        "  dataset = TensorDataset(X, y, idxs)\n",
        "\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "744K7mpLiO2K"
      },
      "outputs": [],
      "source": [
        "# setup dataloaders based on previous dataset split\n",
        "ds_train = get_dataset(df_train, 'feats', 'emotion')\n",
        "ds_val = get_dataset(df_val, 'feats', 'emotion')\n",
        "ds_test = get_dataset(df_test, 'feats', 'emotion')\n",
        "\n",
        "dl_train = DataLoader(ds_train, batch_size=64, shuffle=True)\n",
        "dl_val = DataLoader(ds_val, batch_size=1, shuffle=False)\n",
        "dl_test = DataLoader(ds_test, batch_size=1, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uof__9L0kOiE"
      },
      "source": [
        "# Load and Evaluate Pretrained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "UrspAt84bYJm",
        "outputId": "35b52ef8-3d73-4025-c43f-0825a626cb75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File downloaded to: data/ravdess/model/ravdess_model.pth\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('data/ravdess/model/ravdess_model.pth')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# get checkpoint\n",
        "ckpt_link = 'https://uni-bielefeld.sciebo.de/s/eiOiBrhuOENmo0p/download'\n",
        "ckpt_path = utils.download_file(ckpt_link,\n",
        "                                'ravdess_model.pth',\n",
        "                                cache_dir='./data/ravdess/model',\n",
        "                                extract=False,\n",
        "                                force_download=False\n",
        "                                )\n",
        "ckpt_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecIc95PzS8Ui",
        "outputId": "911dc530-9995-4eae-d562-bb29eae00ceb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9guXuR1Swjz"
      },
      "source": [
        "# Load and Evaluate Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RH7RBT4qSwRR",
        "outputId": "d9a8f6df-fc2e-4a91-b600-644ad4d4dfbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-e100899499d6>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(ckpt_path, map_location='cpu'))\n"
          ]
        }
      ],
      "source": [
        "# To load the best model:\n",
        "model = models.ResNet(len(LABELS))\n",
        "model.load_state_dict(torch.load(ckpt_path, map_location='cpu'))\n",
        "model.to(device);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-Td_Q1HVdM0",
        "outputId": "46e3f998-16ea-4d0a-a5e2-64698fc8d964"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Loss: 0.2150, Evaluation Accuracy: 0.9401\n",
            "Evaluation Loss: 0.1781, Evaluation Accuracy: 0.9375\n",
            "Evaluation Loss: 0.2852, Evaluation Accuracy: 0.9236\n"
          ]
        }
      ],
      "source": [
        "evaluate.evaluate_model(model, dl_train, criterion, device)\n",
        "evaluate.evaluate_model(model, dl_val, criterion, device)\n",
        "_, _, test_preds, test_probs = evaluate.evaluate_model(model, dl_test, criterion, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Qp3rvXN0bYJn",
        "outputId": "bdf13cb4-8076-416c-8fba-41108fb2f055",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9236111111111112"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# load probabilities and predictions into dataframe for test dataset\n",
        "df_test['pred'] = test_preds\n",
        "df_test['prob'] = test_probs\n",
        "test_corr = df_test['emotion'] == df_test['pred']\n",
        "test_corr.astype(int).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOEgF_acbYJn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}